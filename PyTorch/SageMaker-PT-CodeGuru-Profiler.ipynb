{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and push image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  10.75kB\n",
      "Step 1/3 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.9.0-cpu-py38\n",
      "1.9.0-cpu-py38: Pulling from pytorch-inference\n",
      "f3ef4ff62e0d: Pulling fs layer\n",
      "d25595960014: Pulling fs layer\n",
      "7d0257ac10f7: Pulling fs layer\n",
      "eb7d55e09844: Pulling fs layer\n",
      "2ddbce0d4ab8: Pulling fs layer\n",
      "47c9313de682: Pulling fs layer\n",
      "d0219780fbef: Pulling fs layer\n",
      "cc477482d2a4: Pulling fs layer\n",
      "ae34c1ab11cf: Pulling fs layer\n",
      "d5fd5cb88999: Pulling fs layer\n",
      "0c8e7c9b1a7e: Pulling fs layer\n",
      "186a4febd299: Pulling fs layer\n",
      "ad1150ade9d0: Pulling fs layer\n",
      "05ee92511d89: Pulling fs layer\n",
      "7f34de5f4408: Pulling fs layer\n",
      "72c133f8d094: Pulling fs layer\n",
      "675dc66d6f82: Pulling fs layer\n",
      "3f30eb65e5cf: Pulling fs layer\n",
      "514ad8d70c7f: Pulling fs layer\n",
      "c37521e4bf36: Pulling fs layer\n",
      "491357517939: Pulling fs layer\n",
      "eb7d55e09844: Waiting\n",
      "2ddbce0d4ab8: Waiting\n",
      "47c9313de682: Waiting\n",
      "d0219780fbef: Waiting\n",
      "cc477482d2a4: Waiting\n",
      "ae34c1ab11cf: Waiting\n",
      "d5fd5cb88999: Waiting\n",
      "0c8e7c9b1a7e: Waiting\n",
      "186a4febd299: Waiting\n",
      "ad1150ade9d0: Waiting\n",
      "05ee92511d89: Waiting\n",
      "7f34de5f4408: Waiting\n",
      "72c133f8d094: Waiting\n",
      "675dc66d6f82: Waiting\n",
      "3f30eb65e5cf: Waiting\n",
      "514ad8d70c7f: Waiting\n",
      "c37521e4bf36: Waiting\n",
      "491357517939: Waiting\n",
      "7d0257ac10f7: Download complete\n",
      "f3ef4ff62e0d: Verifying Checksum\n",
      "f3ef4ff62e0d: Download complete\n",
      "2ddbce0d4ab8: Verifying Checksum\n",
      "2ddbce0d4ab8: Download complete\n",
      "47c9313de682: Verifying Checksum\n",
      "47c9313de682: Download complete\n",
      "f3ef4ff62e0d: Pull complete\n",
      "eb7d55e09844: Verifying Checksum\n",
      "eb7d55e09844: Download complete\n",
      "d25595960014: Verifying Checksum\n",
      "d25595960014: Download complete\n",
      "cc477482d2a4: Verifying Checksum\n",
      "cc477482d2a4: Download complete\n",
      "d0219780fbef: Verifying Checksum\n",
      "d0219780fbef: Download complete\n",
      "ae34c1ab11cf: Verifying Checksum\n",
      "ae34c1ab11cf: Download complete\n",
      "0c8e7c9b1a7e: Verifying Checksum\n",
      "0c8e7c9b1a7e: Download complete\n",
      "ad1150ade9d0: Verifying Checksum\n",
      "ad1150ade9d0: Download complete\n",
      "05ee92511d89: Verifying Checksum\n",
      "05ee92511d89: Download complete\n",
      "d5fd5cb88999: Verifying Checksum\n",
      "d5fd5cb88999: Download complete\n",
      "72c133f8d094: Verifying Checksum\n",
      "72c133f8d094: Download complete\n",
      "675dc66d6f82: Verifying Checksum\n",
      "675dc66d6f82: Download complete\n",
      "3f30eb65e5cf: Verifying Checksum\n",
      "3f30eb65e5cf: Download complete\n",
      "514ad8d70c7f: Verifying Checksum\n",
      "514ad8d70c7f: Download complete\n",
      "c37521e4bf36: Verifying Checksum\n",
      "c37521e4bf36: Download complete\n",
      "491357517939: Verifying Checksum\n",
      "491357517939: Download complete\n",
      "7f34de5f4408: Verifying Checksum\n",
      "7f34de5f4408: Download complete\n",
      "186a4febd299: Verifying Checksum\n",
      "186a4febd299: Download complete\n",
      "d25595960014: Pull complete\n",
      "7d0257ac10f7: Pull complete\n",
      "eb7d55e09844: Pull complete\n",
      "2ddbce0d4ab8: Pull complete\n",
      "47c9313de682: Pull complete\n",
      "d0219780fbef: Pull complete\n",
      "cc477482d2a4: Pull complete\n",
      "ae34c1ab11cf: Pull complete\n",
      "d5fd5cb88999: Pull complete\n",
      "0c8e7c9b1a7e: Pull complete\n",
      "186a4febd299: Pull complete\n",
      "ad1150ade9d0: Pull complete\n",
      "05ee92511d89: Pull complete\n",
      "7f34de5f4408: Pull complete\n",
      "72c133f8d094: Pull complete\n",
      "675dc66d6f82: Pull complete\n",
      "3f30eb65e5cf: Pull complete\n",
      "514ad8d70c7f: Pull complete\n",
      "c37521e4bf36: Pull complete\n",
      "491357517939: Pull complete\n",
      "Digest: sha256:8b4c2889e14482d91d7918d38077c310701c45906b0a1a9531076680e6281762\n",
      "Status: Downloaded newer image for 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.9.0-cpu-py38\n",
      " ---> edad66663723\n",
      "Step 2/3 : RUN pip3 install codeguru_profiler_agent\n",
      " ---> Running in 85a1c9c681e5\n",
      "Collecting codeguru_profiler_agent\n",
      "  Downloading codeguru_profiler_agent-1.2.4-py3-none-any.whl (61 kB)\n",
      "Collecting boto3>=1.14.0\n",
      "  Downloading boto3-1.24.36-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.14.0->codeguru_profiler_agent) (0.10.0)\n",
      "Collecting botocore<1.28.0,>=1.27.36\n",
      "  Downloading botocore-1.27.36-py3-none-any.whl (9.0 MB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.36->boto3>=1.14.0->codeguru_profiler_agent) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.36->boto3>=1.14.0->codeguru_profiler_agent) (1.26.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.36->boto3>=1.14.0->codeguru_profiler_agent) (1.16.0)\n",
      "Installing collected packages: botocore, s3transfer, boto3, codeguru-profiler-agent\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.21.60\n",
      "    Uninstalling botocore-1.21.60:\n",
      "      Successfully uninstalled botocore-1.21.60\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.5.0\n",
      "    Uninstalling s3transfer-0.5.0:\n",
      "      Successfully uninstalled s3transfer-0.5.0\n",
      "Successfully installed boto3-1.24.36 botocore-1.27.36 codeguru-profiler-agent-1.2.4 s3transfer-0.6.0\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.20.60 requires botocore==1.21.60, but you have botocore 1.27.36 which is incompatible.\n",
      "awscli 1.20.60 requires s3transfer<0.6.0,>=0.5.0, but you have s3transfer 0.6.0 which is incompatible.\n",
      "\u001b[0m\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 85a1c9c681e5\n",
      " ---> 3a1d4521631b\n",
      "Step 3/3 : COPY Files/handler_service.py  /opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\n",
      " ---> 82d07a30e9f2\n",
      "Successfully built 82d07a30e9f2\n",
      "Successfully tagged sagemaker-pt-profiler:latest\n",
      "The push refers to repository [171503325295.dkr.ecr.us-east-1.amazonaws.com/sagemaker-pt-profiler]\n",
      "fbef3b18c6d8: Preparing\n",
      "a27ad3a8a916: Preparing\n",
      "77ed370a3fd1: Preparing\n",
      "96e26b2e8a77: Preparing\n",
      "a307804fdf8b: Preparing\n",
      "5cc0f5722a41: Preparing\n",
      "a6db19c017f8: Preparing\n",
      "b51aacff698c: Preparing\n",
      "0b754a16db36: Preparing\n",
      "5b1afb4a605a: Preparing\n",
      "a98f4a7568e6: Preparing\n",
      "e6edda8500e4: Preparing\n",
      "c2d6116b18c6: Preparing\n",
      "b960da073da9: Preparing\n",
      "58d122106d65: Preparing\n",
      "b0a5b545ad92: Preparing\n",
      "c0eab8146a38: Preparing\n",
      "c2fdf82f1646: Preparing\n",
      "d24d62a12584: Preparing\n",
      "59d903e2da45: Preparing\n",
      "2737b431a6c7: Preparing\n",
      "57f665afe158: Preparing\n",
      "da55b45d310b: Preparing\n",
      "c2d6116b18c6: Waiting\n",
      "b960da073da9: Waiting\n",
      "58d122106d65: Waiting\n",
      "b0a5b545ad92: Waiting\n",
      "c0eab8146a38: Waiting\n",
      "c2fdf82f1646: Waiting\n",
      "d24d62a12584: Waiting\n",
      "59d903e2da45: Waiting\n",
      "2737b431a6c7: Waiting\n",
      "57f665afe158: Waiting\n",
      "da55b45d310b: Waiting\n",
      "5cc0f5722a41: Waiting\n",
      "a6db19c017f8: Waiting\n",
      "0b754a16db36: Waiting\n",
      "b51aacff698c: Waiting\n",
      "5b1afb4a605a: Waiting\n",
      "e6edda8500e4: Waiting\n",
      "a98f4a7568e6: Waiting\n",
      "77ed370a3fd1: Layer already exists\n",
      "96e26b2e8a77: Layer already exists\n",
      "a307804fdf8b: Layer already exists\n",
      "5cc0f5722a41: Layer already exists\n",
      "a6db19c017f8: Layer already exists\n",
      "b51aacff698c: Layer already exists\n",
      "0b754a16db36: Layer already exists\n",
      "a98f4a7568e6: Layer already exists\n",
      "5b1afb4a605a: Layer already exists\n",
      "e6edda8500e4: Layer already exists\n",
      "c2d6116b18c6: Layer already exists\n",
      "b960da073da9: Layer already exists\n",
      "58d122106d65: Layer already exists\n",
      "b0a5b545ad92: Layer already exists\n",
      "c0eab8146a38: Layer already exists\n",
      "c2fdf82f1646: Layer already exists\n",
      "d24d62a12584: Layer already exists\n",
      "59d903e2da45: Layer already exists\n",
      "2737b431a6c7: Layer already exists\n",
      "57f665afe158: Layer already exists\n",
      "da55b45d310b: Layer already exists\n",
      "fbef3b18c6d8: Pushed\n",
      "a27ad3a8a916: Pushed\n",
      "latest: digest: sha256:c55c4220b8763c2aa8283989835651598c4dc45d14991f923977bdbe60922922 size: 5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (InvalidParameterException) when calling the GetAuthorizationToken operation: Invalid parameter at 'registryIds' failed to satisfy constraint: 'Member must satisfy constraint: [Member must satisfy regular expression pattern: [0-9]{12}]'\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-pt-profiler\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email --registry-ids [763104351884,${account}])\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-pt-profiler:latest\".format(account_id,region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy our Model to an Endpoint\n",
    "Our container has been pushed to ECR and our Model is in S3 now we have everything we need to Deploy to a SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"sagemaker-sample-files\"\n",
    "key = \"datasets/image/MNIST/model/pytorch-training-2020-11-21-22-02-56-203/model.tar.gz\"\n",
    "\n",
    "pt_model= \"s3://{}/{}\".format(bucket,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# defining model and loading weights to it.\n",
    "def model_fn(model_dir): \n",
    "    model = Net()   \n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# data preprocessing\n",
    "def input_fn(request_body, request_content_type):\n",
    "    assert request_content_type == \"application/json\"\n",
    "    data = json.loads(request_body)[\"inputs\"]\n",
    "    data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "    return data\n",
    "\n",
    "\n",
    "# inference\n",
    "def predict_fn(input_object, model):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_object)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# postprocess\n",
    "def output_fn(predictions, content_type):\n",
    "    assert content_type == \"application/json\"\n",
    "    res = predictions.cpu().numpy().tolist()\n",
    "    return json.dumps(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('codeguruprofiler')\n",
    "pytorch_profiling_group_name = \"SageMaker-PyTorch\"\n",
    "\n",
    "\n",
    "retrieve_latest_features_boto3_client_create_profiling_group = client.create_profiling_group(\n",
    "    profilingGroupName=pytorch_profiling_group_name,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    env={\n",
    "    \"PROFILING_GROUP_NAME\": pytorch_profiling_group_name\n",
    "    },\n",
    "    model_data=pt_model,\n",
    "    framework_version=\"1.9.0\",\n",
    "    image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!CPU times: user 467 ms, sys: 0 ns, total: 467 ms\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "instance_type = \"ml.c4.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 10s, sys: 7.39 s, total: 16min 17s\n",
      "Wall time: 27min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "import numpy as np\n",
    "for i in range (0,20000):\n",
    "    dummy_data = {\"inputs\": np.random.rand(16, 1, 28, 28).tolist()}\n",
    "    res = predictor.predict(dummy_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
