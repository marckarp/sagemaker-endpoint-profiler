{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and push image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "region = \"us-east-1\"\n",
    "image_uri = image_uris.retrieve(framework='pytorch',region=region,version='1.9.0',image_scope='inference',instance_type='ml.c5.4xlarge')\n",
    "account_id = image_uri.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --region $region --no-include-email --registry-ids $account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Dockerfile\n",
    "with open('container/Dockerfile', 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "# Update the image_uri\n",
    "filedata = filedata.replace('{image_uri}', image_uri)\n",
    "\n",
    "# Write the Dockerfile out again\n",
    "with open('container/Dockerfile', 'w') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  10.75kB\n",
      "Step 1/3 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.9.0-cpu-py38\n",
      " ---> edad66663723\n",
      "Step 2/3 : RUN pip3 install codeguru_profiler_agent\n",
      " ---> Using cache\n",
      " ---> 3a1d4521631b\n",
      "Step 3/3 : COPY Files/handler_service.py  /opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\n",
      " ---> Using cache\n",
      " ---> 82d07a30e9f2\n",
      "Successfully built 82d07a30e9f2\n",
      "Successfully tagged sagemaker-pt-profiler:latest\n",
      "The push refers to repository [171503325295.dkr.ecr.us-east-1.amazonaws.com/sagemaker-pt-profiler]\n",
      "fbef3b18c6d8: Preparing\n",
      "a27ad3a8a916: Preparing\n",
      "77ed370a3fd1: Preparing\n",
      "96e26b2e8a77: Preparing\n",
      "a307804fdf8b: Preparing\n",
      "5cc0f5722a41: Preparing\n",
      "a6db19c017f8: Preparing\n",
      "b51aacff698c: Preparing\n",
      "0b754a16db36: Preparing\n",
      "5b1afb4a605a: Preparing\n",
      "a98f4a7568e6: Preparing\n",
      "e6edda8500e4: Preparing\n",
      "c2d6116b18c6: Preparing\n",
      "b960da073da9: Preparing\n",
      "58d122106d65: Preparing\n",
      "b0a5b545ad92: Preparing\n",
      "c0eab8146a38: Preparing\n",
      "c2fdf82f1646: Preparing\n",
      "d24d62a12584: Preparing\n",
      "59d903e2da45: Preparing\n",
      "2737b431a6c7: Preparing\n",
      "57f665afe158: Preparing\n",
      "da55b45d310b: Preparing\n",
      "5cc0f5722a41: Waiting\n",
      "a6db19c017f8: Waiting\n",
      "b51aacff698c: Waiting\n",
      "0b754a16db36: Waiting\n",
      "5b1afb4a605a: Waiting\n",
      "a98f4a7568e6: Waiting\n",
      "e6edda8500e4: Waiting\n",
      "c2d6116b18c6: Waiting\n",
      "b960da073da9: Waiting\n",
      "58d122106d65: Waiting\n",
      "b0a5b545ad92: Waiting\n",
      "c0eab8146a38: Waiting\n",
      "c2fdf82f1646: Waiting\n",
      "d24d62a12584: Waiting\n",
      "59d903e2da45: Waiting\n",
      "2737b431a6c7: Waiting\n",
      "57f665afe158: Waiting\n",
      "da55b45d310b: Waiting\n",
      "77ed370a3fd1: Layer already exists\n",
      "a27ad3a8a916: Layer already exists\n",
      "fbef3b18c6d8: Layer already exists\n",
      "a307804fdf8b: Layer already exists\n",
      "5cc0f5722a41: Layer already exists\n",
      "96e26b2e8a77: Layer already exists\n",
      "0b754a16db36: Layer already exists\n",
      "a6db19c017f8: Layer already exists\n",
      "b51aacff698c: Layer already exists\n",
      "5b1afb4a605a: Layer already exists\n",
      "a98f4a7568e6: Layer already exists\n",
      "e6edda8500e4: Layer already exists\n",
      "c2d6116b18c6: Layer already exists\n",
      "b960da073da9: Layer already exists\n",
      "b0a5b545ad92: Layer already exists\n",
      "c2fdf82f1646: Layer already exists\n",
      "58d122106d65: Layer already exists\n",
      "c0eab8146a38: Layer already exists\n",
      "d24d62a12584: Layer already exists\n",
      "2737b431a6c7: Layer already exists\n",
      "59d903e2da45: Layer already exists\n",
      "da55b45d310b: Layer already exists\n",
      "57f665afe158: Layer already exists\n",
      "latest: digest: sha256:c55c4220b8763c2aa8283989835651598c4dc45d14991f923977bdbe60922922 size: 5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-pt-profiler\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email --registry-ids 763104351884)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-pt-profiler:latest\".format(account_id,region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy our Model to an Endpoint\n",
    "Our container has been pushed to ECR and our Model is in S3 now we have everything we need to Deploy to a SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"sagemaker-sample-files\"\n",
    "key = \"datasets/image/MNIST/model/pytorch-training-2020-11-21-22-02-56-203/model.tar.gz\"\n",
    "\n",
    "pt_model= \"s3://{}/{}\".format(bucket,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# defining model and loading weights to it.\n",
    "def model_fn(model_dir): \n",
    "    model = Net()   \n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# data preprocessing\n",
    "def input_fn(request_body, request_content_type):\n",
    "    assert request_content_type == \"application/json\"\n",
    "    data = json.loads(request_body)[\"inputs\"]\n",
    "    data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "    return data\n",
    "\n",
    "\n",
    "# inference\n",
    "def predict_fn(input_object, model):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_object)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# postprocess\n",
    "def output_fn(predictions, content_type):\n",
    "    assert content_type == \"application/json\"\n",
    "    res = predictions.cpu().numpy().tolist()\n",
    "    return json.dumps(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('codeguruprofiler')\n",
    "pytorch_profiling_group_name = \"SageMaker-PyTorch\"\n",
    "\n",
    "retrieve_latest_features_boto3_client_create_profiling_group = client.create_profiling_group(\n",
    "    profilingGroupName=pytorch_profiling_group_name,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    env={\n",
    "    \"PROFILING_GROUP_NAME\": pytorch_profiling_group_name\n",
    "    },\n",
    "    model_data=pt_model,\n",
    "    framework_version=\"1.9.0\",\n",
    "    image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "instance_type = \"ml.c4.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "dummy_data = {\"inputs\": np.random.rand(16, 1, 28, 28).tolist()}\n",
    "\n",
    "timeout = 300 #5min/300s\n",
    "\n",
    "timeout_start = time.time()\n",
    "\n",
    "while time.time() < timeout_start + timeout:\n",
    "    test = 0\n",
    "    if test == 5:\n",
    "        break\n",
    "    test -= 1\n",
    "    prediction = predictor.predict(dummy_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
