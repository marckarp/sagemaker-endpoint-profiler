{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and push image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  7.168kB\n",
      "Step 1/3 : FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.9.0-cpu-py38\n",
      " ---> edad66663723\n",
      "Step 2/3 : RUN pip3 install codeguru_profiler_agent\n",
      " ---> Using cache\n",
      " ---> c8cfa4f9a16d\n",
      "Step 3/3 : COPY Files/handler_service.py opt/conda/lib/python3.8/site-packages/sagemaker_pytorch_serving_container/handler_service.py\n",
      " ---> Using cache\n",
      " ---> 3e039b552064\n",
      "Successfully built 3e039b552064\n",
      "Successfully tagged sagemaker-pt-profiler:latest\n",
      "The push refers to repository [171503325295.dkr.ecr.us-east-1.amazonaws.com/sagemaker-pt-profiler]\n",
      "d8aada0e56d4: Preparing\n",
      "710c89c0224b: Preparing\n",
      "77ed370a3fd1: Preparing\n",
      "96e26b2e8a77: Preparing\n",
      "a307804fdf8b: Preparing\n",
      "5cc0f5722a41: Preparing\n",
      "a6db19c017f8: Preparing\n",
      "b51aacff698c: Preparing\n",
      "0b754a16db36: Preparing\n",
      "5b1afb4a605a: Preparing\n",
      "a98f4a7568e6: Preparing\n",
      "e6edda8500e4: Preparing\n",
      "c2d6116b18c6: Preparing\n",
      "b960da073da9: Preparing\n",
      "58d122106d65: Preparing\n",
      "b0a5b545ad92: Preparing\n",
      "c0eab8146a38: Preparing\n",
      "c2fdf82f1646: Preparing\n",
      "d24d62a12584: Preparing\n",
      "59d903e2da45: Preparing\n",
      "2737b431a6c7: Preparing\n",
      "57f665afe158: Preparing\n",
      "da55b45d310b: Preparing\n",
      "b960da073da9: Waiting\n",
      "58d122106d65: Waiting\n",
      "b0a5b545ad92: Waiting\n",
      "c0eab8146a38: Waiting\n",
      "c2fdf82f1646: Waiting\n",
      "d24d62a12584: Waiting\n",
      "59d903e2da45: Waiting\n",
      "2737b431a6c7: Waiting\n",
      "57f665afe158: Waiting\n",
      "da55b45d310b: Waiting\n",
      "5cc0f5722a41: Waiting\n",
      "5b1afb4a605a: Waiting\n",
      "a98f4a7568e6: Waiting\n",
      "a6db19c017f8: Waiting\n",
      "e6edda8500e4: Waiting\n",
      "b51aacff698c: Waiting\n",
      "c2d6116b18c6: Waiting\n",
      "0b754a16db36: Waiting\n",
      "96e26b2e8a77: Layer already exists\n",
      "77ed370a3fd1: Layer already exists\n",
      "a307804fdf8b: Layer already exists\n",
      "d8aada0e56d4: Layer already exists\n",
      "710c89c0224b: Layer already exists\n",
      "5cc0f5722a41: Layer already exists\n",
      "a6db19c017f8: Layer already exists\n",
      "0b754a16db36: Layer already exists\n",
      "b51aacff698c: Layer already exists\n",
      "5b1afb4a605a: Layer already exists\n",
      "e6edda8500e4: Layer already exists\n",
      "a98f4a7568e6: Layer already exists\n",
      "c2d6116b18c6: Layer already exists\n",
      "58d122106d65: Layer already exists\n",
      "b960da073da9: Layer already exists\n",
      "b0a5b545ad92: Layer already exists\n",
      "c0eab8146a38: Layer already exists\n",
      "c2fdf82f1646: Layer already exists\n",
      "d24d62a12584: Layer already exists\n",
      "59d903e2da45: Layer already exists\n",
      "2737b431a6c7: Layer already exists\n",
      "57f665afe158: Layer already exists\n",
      "da55b45d310b: Layer already exists\n",
      "latest: digest: sha256:0274fd24e9d788195b33af1770571eb5bea406d005253f0c867b83413a082f9f size: 5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-pt-profiler\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.Session().region_name\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/sagemaker-pt-profiler:latest\".format(account_id,region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy our Model to an Endpoint\n",
    "Our container has been pushed to ECR and our Model is in S3 now we have everything we need to Deploy to a SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = \"sagemaker-sample-files\"\n",
    "key = \"datasets/image/MNIST/model/pytorch-training-2020-11-21-22-02-56-203/model.tar.gz\"\n",
    "\n",
    "pt_model= \"s3://{}/{}\".format(bucket,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# Based on https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# defining model and loading weights to it.\n",
    "def model_fn(model_dir): \n",
    "    model = Net()   \n",
    "    with open(os.path.join(model_dir, \"model.pth\"), \"rb\") as f:\n",
    "        model.load_state_dict(torch.load(f))\n",
    "    model.to(device).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# data preprocessing\n",
    "def input_fn(request_body, request_content_type):\n",
    "    assert request_content_type == \"application/json\"\n",
    "    data = json.loads(request_body)[\"inputs\"]\n",
    "    data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "    return data\n",
    "\n",
    "\n",
    "# inference\n",
    "def predict_fn(input_object, model):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_object)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# postprocess\n",
    "def output_fn(predictions, content_type):\n",
    "    assert content_type == \"application/json\"\n",
    "    res = predictions.cpu().numpy().tolist()\n",
    "    return json.dumps(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.local import LocalSession\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    model_data=pt_model,\n",
    "    framework_version=\"1.9.0\",\n",
    "    image_uri=image_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!CPU times: user 467 ms, sys: 0 ns, total: 467 ms\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "instance_type = \"ml.c4.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 10s, sys: 7.39 s, total: 16min 17s\n",
      "Wall time: 27min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "import numpy as np\n",
    "for i in range (0,20000):\n",
    "    dummy_data = {\"inputs\": np.random.rand(16, 1, 28, 28).tolist()}\n",
    "    res = predictor.predict(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
